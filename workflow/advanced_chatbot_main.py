"""
Advanced Chatbot System - Main Application
TÃ­ch há»£p Ä‘áº§y Ä‘á»§ 4 loáº¡i handler: QnA, Search Information, Send Email, Calendar Build
"""

import os
import sys
import asyncio
from typing import List, Optional

# Add project root to path and load config
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

# Import config from config directory
from config.system_config import config, print_config_status

import chainlit as cl
from workflow.main_workflow_manager import MainWorkflowManager, WorkflowResponse

# Import for agent integration (when available)
try:
    from llm.base import AgentClient
    from pydantic_ai.models.gemini import GeminiModel
    from pydantic_ai.providers.google_gla import GoogleGLAProvider
    AGENT_AVAILABLE = True
except ImportError:
    AGENT_AVAILABLE = False

# Global variables
workflow_manager = None
agent_client = None

def initialize_system():
    """
    Khá»Ÿi táº¡o toÃ n bá»™ há»‡ thá»‘ng
    """
    global workflow_manager, agent_client
    
    try:
        # Validate environment first
        validation_result = config.validate_environment()
        is_valid = validation_result["valid"]
        missing_keys = validation_result["missing"]
        if not is_valid:
            print(f"âŒ Missing API keys: {', '.join(missing_keys)}")
            print("   Please check your .env file in project root")
            return False
        
        # Initialize workflow manager
        workflow_manager = MainWorkflowManager(collection_name=config.DEFAULT_COLLECTION_NAME)
        
        # Initialize LLM agent for advanced processing (if available)
        if AGENT_AVAILABLE:
            provider = GoogleGLAProvider(api_key=config.GEMINI_API_KEY)
            model = GeminiModel('gemini-2.0-flash', provider=provider)
            
            # Create agent with comprehensive system prompt
            system_prompt = f"""
            Báº¡n lÃ  má»™t AI Assistant thÃ´ng minh cho há»‡ thá»‘ng chatbot cá»§a {config.SCHOOL_NAME}.
            
            Báº¡n cÃ³ thá»ƒ xá»­ lÃ½ 4 loáº¡i yÃªu cáº§u chÃ­nh:
            1. QnA: Tráº£ lá»i cÃ¢u há»i vá» trÆ°á»ng há»c, chÃ­nh sÃ¡ch, há»c phÃ­, mÃ´n há»c
            2. Search Information: TÃ¬m kiáº¿m thÃ´ng tin chi tiáº¿t tá»« web vÃ  tÃ i liá»‡u
            3. Send Email: Soáº¡n vÃ  gá»­i email tháº¯c máº¯c Ä‘áº¿n phÃ²ng ban
            4. Calendar Build: Táº¡o lá»‹ch há»c táº­p vÃ  cÃ¡ nhÃ¢n
            
            HÃ£y luÃ´n:
            - Tráº£ lá»i má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch
            - Chá»‰ cung cáº¥p thÃ´ng tin liÃªn quan Ä‘áº¿n giÃ¡o dá»¥c vÃ  trÆ°á»ng há»c
            - Há»i thÃªm thÃ´ng tin khi cáº§n thiáº¿t
            - HÆ°á»›ng dáº«n user cÃ¡ch sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng
            
            TrÃ¡nh:
            - ThÃ´ng tin khÃ´ng liÃªn quan Ä‘áº¿n trÆ°á»ng há»c
            - Ná»™i dung khÃ´ng phÃ¹ há»£p
            - ÄÆ°a ra thÃ´ng tin sai lá»‡ch
            """
            
            # Note: Agent integration will be added when needed
            print("âœ… LLM Agent integration available")
        else:
            print("âš ï¸ LLM Agent dependencies not available, using basic mode")
        
        print(f"âœ… Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng cho {config.SCHOOL_NAME}!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o há»‡ thá»‘ng: {e}")
        return False

@cl.on_chat_start
async def start():
    """
    Khá»Ÿi táº¡o chat session
    """
    # Initialize system if not done
    if workflow_manager is None:
        success = initialize_system()
        if not success:
            await cl.Message(
                content="âŒ CÃ³ lá»—i trong viá»‡c khá»Ÿi táº¡o há»‡ thá»‘ng. Vui lÃ²ng thá»­ láº¡i sau."
            ).send()
            return
    
    # Welcome message
    welcome_message = f"""
ğŸ“ **CHÃ€O Má»ªNG Äáº¾N Há»† THá»NG CHATBOT Cá»¦A {config.SCHOOL_NAME.upper()}!** 

TÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n vá»›i:

ğŸ“š **1. CÃ¢u há»i & Giáº£i Ä‘Ã¡p (QnA)**
   â€¢ ThÃ´ng tin vá» há»c phÃ­, mÃ´n há»c, quy Ä‘á»‹nh
   â€¢ ChÃ­nh sÃ¡ch vÃ  thá»§ tá»¥c cá»§a trÆ°á»ng
   â€¢ FAQ vÃ  hÆ°á»›ng dáº«n sinh viÃªn

ğŸ” **2. TÃ¬m kiáº¿m thÃ´ng tin (Search)**
   â€¢ TÃ¬m kiáº¿m thÃ´ng tin chi tiáº¿t tá»« web
   â€¢ NghiÃªn cá»©u vá» chá»§ Ä‘á» giÃ¡o dá»¥c
   â€¢ ThÃ´ng tin bá»• sung tá»« tÃ i liá»‡u

ğŸ“§ **3. Gá»­i tháº¯c máº¯c qua Email**
   â€¢ Soáº¡n email gá»­i Ä‘áº¿n phÃ²ng ban
   â€¢ Tá»± Ä‘á»™ng phÃ¢n loáº¡i vÃ  route email
   â€¢ Há»— trá»£ follow-up vÃ  tracking

ğŸ“… **4. Táº¡o lá»‹ch há»c táº­p**
   â€¢ Táº¡o lá»‹ch há»c cÃ¡ nhÃ¢n
   â€¢ Import tá»« file thá»i khÃ³a biá»ƒu
   â€¢ Export CSV vÃ  Google Calendar

ğŸ’¡ **CÃ¡ch sá»­ dá»¥ng:**
   â€¢ Há»i trá»±c tiáº¿p cÃ¢u há»i cá»§a báº¡n
   â€¢ Upload file náº¿u cáº§n (thá»i khÃ³a biá»ƒu, tÃ i liá»‡u)
   â€¢ LÃ m theo hÆ°á»›ng dáº«n cho tá»«ng tÃ­nh nÄƒng

**HÃ£y báº¯t Ä‘áº§u báº±ng cÃ¡ch há»i tÃ´i báº¥t ká»³ Ä‘iá»u gÃ¬ vá» trÆ°á»ng há»c!** ğŸš€
    """
    
    await cl.Message(content=welcome_message).send()

@cl.on_message
async def main(message: cl.Message):
    """
    Xá»­ lÃ½ message tá»« user
    """
    try:
        # Get session ID
        session_id = cl.user_session.get("id", "default_session")
        
        # Get file attachments if any
        file_paths = []
        if message.elements:
            for element in message.elements:
                if hasattr(element, 'path'):
                    file_paths.append(element.path)
        
        # Process with workflow manager
        if workflow_manager:
            # Show typing indicator
            async with cl.Step(name="Äang xá»­ lÃ½...") as step:
                step.output = "PhÃ¢n tÃ­ch yÃªu cáº§u vÃ  tÃ¬m kiáº¿m thÃ´ng tin..."
                
                # Process user input
                response = workflow_manager.process_user_input(
                    user_input=message.content,
                    session_id=session_id,
                    file_paths=file_paths if file_paths else None
                )
                
                step.output = "HoÃ n táº¥t xá»­ lÃ½!"
            
            # Format and send response
            formatted_response = format_workflow_response(response)
            await cl.Message(content=formatted_response).send()
            
            # Send additional actions if available
            if response.suggested_actions:
                actions_text = "ğŸ’¡ **Báº¡n cÃ³ thá»ƒ:**\n" + "\n".join([f"   â€¢ {action}" for action in response.suggested_actions])
                await cl.Message(content=actions_text).send()
        
        else:
            await cl.Message(
                content="âŒ Há»‡ thá»‘ng chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o. Vui lÃ²ng refresh trang vÃ  thá»­ láº¡i."
            ).send()
    
    except Exception as e:
        error_message = f"""
âŒ **CÃ“ Lá»–I Xáº¢Y RA**

Lá»—i: {str(e)}

ğŸ”§ **HÆ°á»›ng dáº«n kháº¯c phá»¥c:**
â€¢ Thá»­ láº¡i vá»›i cÃ¢u há»i Ä‘Æ¡n giáº£n hÆ¡n
â€¢ Kiá»ƒm tra file upload (náº¿u cÃ³)
â€¢ LiÃªn há»‡ support náº¿u lá»—i tiáº¿p tá»¥c

ğŸ’¡ **Hoáº·c báº¡n cÃ³ thá»ƒ:**
â€¢ Há»i vá» thÃ´ng tin cÆ¡ báº£n cá»§a trÆ°á»ng
â€¢ TÃ¬m kiáº¿m thÃ´ng tin trÃªn web
â€¢ YÃªu cáº§u há»— trá»£ qua email
        """
        
        await cl.Message(content=error_message).send()

def format_workflow_response(response: WorkflowResponse) -> str:
    """
    Format workflow response thÃ nh message Ä‘áº¹p
    """
    # Base message
    formatted_message = response.message
    
    # Add response type emoji
    type_emojis = {
        "qna": "ğŸ’¬",
        "search": "ğŸ”", 
        "email_draft": "ğŸ“§",
        "email_sent": "âœ…",
        "calendar_preview": "ğŸ“…",
        "calendar_approved": "âœ…",
        "google_calendar_code": "ğŸ’»",
        "error": "âŒ",
        "confirmation": "â“"
    }
    
    emoji = type_emojis.get(response.response_type, "ğŸ’­")
    
    # Add metadata if available
    metadata_parts = []
    
    if response.data:
        if "confidence" in response.data:
            confidence = response.data["confidence"]
            if confidence < 0.5:
                metadata_parts.append(f"âš ï¸ Äá»™ tin cáº­y: {confidence:.1%} (tháº¥p)")
            elif confidence > 0.8:
                metadata_parts.append(f"âœ… Äá»™ tin cáº­y: {confidence:.1%} (cao)")
        
        if "sources" in response.data and response.data["sources"]:
            sources_text = ", ".join(response.data["sources"])
            metadata_parts.append(f"ğŸ“š Nguá»“n: {sources_text}")
    
    # Combine all parts
    final_parts = [f"{emoji} {formatted_message}"]
    
    if metadata_parts:
        final_parts.append("")
        final_parts.append("---")
        final_parts.extend(metadata_parts)
    
    return "\n".join(final_parts)

@cl.on_stop
async def stop():
    """
    Cleanup when chat stops
    """
    print("Chat session ended")

# File upload handler
@cl.on_file_upload(accept=["text/plain", "application/pdf", "application/vnd.ms-excel", ".xlsx", ".csv"])
async def handle_file_upload(file_path: str):
    """
    Xá»­ lÃ½ file upload
    """
    await cl.Message(
        content=f"ğŸ“ ÄÃ£ nháº­n file: `{os.path.basename(file_path)}`\n\nVui lÃ²ng mÃ´ táº£ báº¡n muá»‘n lÃ m gÃ¬ vá»›i file nÃ y?"
    ).send()

if __name__ == "__main__":
    # Initialize system before starting
    print("ğŸš€ Äang khá»Ÿi táº¡o Advanced Chatbot System...")
    
    success = initialize_system()
    if success:
        print("ğŸ¯ Há»‡ thá»‘ng sáºµn sÃ ng! Khá»Ÿi Ä‘á»™ng Chainlit...")
        # Chainlit will be started with: chainlit run advanced_chatbot_main.py
    else:
        print("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o há»‡ thá»‘ng!")
        sys.exit(1)
