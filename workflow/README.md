# Advanced Chatbot System - Setup & Usage Guide

## üéØ T·ªïng quan

H·ªá th·ªëng chatbot n√¢ng cao n√†y cung c·∫•p 4 t√≠nh nƒÉng ch√≠nh:
1. **QnA**: Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ tr∆∞·ªùng h·ªçc v·ªõi RAG system
2. **Search Information**: T√¨m ki·∫øm th√¥ng tin t·ª´ web v√† documents  
3. **Send Email**: So·∫°n v√† g·ª≠i email ƒë·∫øn ph√≤ng ban
4. **Calendar Build**: T·∫°o l·ªãch h·ªçc t·∫≠p t·ª´ file th·ªùi kh√≥a bi·ªÉu

## üöÄ C√†i ƒë·∫∑t

### 1. Prerequisites

```bash
# Python 3.8+ required
python --version

# Docker (for Milvus and Redis)
docker --version
docker-compose --version
```

### 2. Install Dependencies

```bash
# Navigate to workflow directory
cd workflow/

# Install Python packages
pip install -r requirements.txt
```

### 3. Setup Database Services

```bash
# Start Milvus and Redis using docker-compose from root directory
cd ..
docker-compose up -d

# Verify services are running
docker-compose ps
```

### 4. Environment Configuration

```bash
# Copy example environment file from project root
cp .env.example .env

# Edit .env file with your API keys and configuration
nano .env
```

Required API keys:
- **GEMINI_API_KEY**: Get from Google AI Studio
- **OPENAI_API_KEY**: Get from OpenAI platform
- **Email credentials**: For SMTP email sending

**Note**: The .env file should be placed in the project root directory, not in the workflow folder.

### 5. Initialize Data

```bash
# Run initial data indexing (modify paths as needed)
python -c "
from src.data.milvus.indexing import MilvusIndexer
indexer = MilvusIndexer(collection_name='school_chatbot', faq_file='src/data/mock_data/HR_FAQ.xlsx')
indexer.run()
print('‚úÖ Data indexed successfully!')
"
```

## üéÆ S·ª≠ d·ª•ng

### Start Chatbot

```bash
# Start the advanced chatbot system
cd workflow/
chainlit run advanced_chatbot_main.py
```

Truy c·∫≠p: http://localhost:8000

### C√°c t√≠nh nƒÉng ch√≠nh

#### 1. üí¨ QnA (Questions & Answers)
```
User: "H·ªçc ph√≠ nƒÉm nay l√† bao nhi·ªÅu?"
Bot: [T√¨m ki·∫øm trong FAQ v√† tr·∫£ l·ªùi v·ªõi ngu·ªìn]
```

#### 2. üîç Search Information  
```
User: "T√¨m th√¥ng tin v·ªÅ h·ªçc b·ªïng ASEAN"
Bot: [T√¨m ki·∫øm web v√† documents, t·ªïng h·ª£p k·∫øt qu·∫£]
```

#### 3. üìß Send Email
```
User: "T√¥i mu·ªën g·ª≠i th·∫Øc m·∫Øc v·ªÅ vi·ªác ƒëƒÉng k√Ω m√¥n h·ªçc"
Bot: [So·∫°n email draft v√† y√™u c·∫ßu x√°c nh·∫≠n]
User: "G·ª¨I"
Bot: [G·ª≠i email v√† th√¥ng b√°o k·∫øt qu·∫£]
```

#### 4. üìÖ Calendar Build
```
User: "T·∫°o l·ªãch h·ªçc cho t√¥i" + upload file th·ªùi kh√≥a bi·ªÉu
Bot: [H·ªèi th√™m th√¥ng tin] ‚Üí [T·∫°o l·ªãch] ‚Üí [Export CSV + Google Calendar code]
```

## üîß C·∫•u h√¨nh n√¢ng cao

### Custom School Information

Edit the centralized configuration in the project root `config.py`:

```python
# In config.py - Department email configuration
ACADEMIC_EMAIL = os.getenv("ACADEMIC_EMAIL", "your_academic_dept@school.edu")
ADMIN_EMAIL = os.getenv("ADMIN_EMAIL", "your_admin_dept@school.edu")
# ... other department emails

# School-specific settings
SCHOOL_NAME = os.getenv("SCHOOL_NAME", "Your University Name")
```

Or update via environment variables in `.env`:
```bash
SCHOOL_NAME=Your University Name
ACADEMIC_EMAIL=daotao@yourschool.edu.vn
ADMIN_EMAIL=hanhchinh@yourschool.edu.vn
# ... other settings
```

### Custom FAQ Data

1. Chu·∫©n b·ªã file Excel v·ªõi columns: `Question`, `Answer`
2. ƒê·∫∑t file v√†o `src/data/mock_data/`
3. Update indexing code:

```python
indexer = MilvusIndexer(
    collection_name="your_collection", 
    faq_file="path/to/your/faq.xlsx"
)
```

### Google Calendar Integration

1. Setup Google Cloud Project
2. Enable Calendar API
3. Download credentials.json
4. Users s·∫Ω nh·∫≠n code Python ƒë·ªÉ import events

## üîç Troubleshooting

### Common Issues

**1. Milvus connection error**
```bash
# Check if Milvus is running
docker-compose ps

# Restart services
docker-compose restart
```

**2. API key errors**
```bash
# Verify environment variables
echo $GEMINI_API_KEY
echo $OPENAI_API_KEY
```

**3. Memory issues**
```bash
# Check Redis connection
redis-cli ping

# Clear Redis cache if needed
redis-cli flushall
```

**4. File upload issues**
- Check file size < 10MB
- Supported formats: txt, pdf, docx, xlsx, csv
- Ensure proper file encoding (UTF-8)

### Debug Mode

Enable debug mode in `.env`:
```
DEBUG=True
LOG_LEVEL=DEBUG
```

Logs will show detailed processing steps.

## üìä Monitoring

### Health Check Endpoints

Add to `advanced_chatbot_main.py`:

```python
@cl.on_startup
async def startup():
    # Health checks
    print("üîç Checking system health...")
    
    # Check Milvus
    try:
        from src.data.milvus.milvus_client import MilvusClient
        client = MilvusClient("test")
        print("‚úÖ Milvus: Connected")
    except:
        print("‚ùå Milvus: Failed")
    
    # Check Redis
    try:
        import redis
        r = redis.StrictRedis()
        r.ping()
        print("‚úÖ Redis: Connected")
    except:
        print("‚ùå Redis: Failed")
```

### Performance Metrics

Monitor:
- Response time per request type
- API call success rates  
- Memory usage
- File processing times

## üîí Security

### Best Practices

1. **API Keys**: Never commit to version control
2. **Input Validation**: All user inputs are validated
3. **Rate Limiting**: Built-in rate limiting
4. **Email**: Validate recipients before sending
5. **File Upload**: Size and type restrictions

### Production Deployment

```bash
# Use production-grade WSGI server
pip install gunicorn

# Run with Gunicorn
gunicorn -w 4 -k uvicorn.workers.UvicornWorker advanced_chatbot_main:app
```

## üìà Scaling

### Horizontal Scaling

1. **Load Balancer**: Nginx + multiple app instances
2. **Database**: Redis Cluster for memory
3. **Vector DB**: Milvus cluster for high availability
4. **Monitoring**: Prometheus + Grafana

### Performance Optimization

1. **Caching**: Aggressive caching of FAQ results
2. **Async**: All I/O operations are async
3. **Batching**: Batch API calls where possible
4. **Connection Pooling**: Reuse DB connections

## ü§ù Contributing

### Code Structure

```
workflow/
‚îú‚îÄ‚îÄ advanced_chatbot_main.py      # Main Chainlit app
‚îú‚îÄ‚îÄ main_workflow_manager.py      # Central orchestrator  
‚îú‚îÄ‚îÄ request_classifier.py         # Request classification
‚îú‚îÄ‚îÄ qna_handler.py                # Q&A processing
‚îú‚îÄ‚îÄ search_handler.py             # Information search
‚îú‚îÄ‚îÄ email_handler.py              # Email functionality
‚îú‚îÄ‚îÄ calendar_handler.py           # Calendar creation
‚îú‚îÄ‚îÄ requirements.txt              # Dependencies
‚îî‚îÄ‚îÄ .env.example                  # Environment template
```

### Adding New Features

1. Create new handler in workflow/
2. Add to main_workflow_manager.py
3. Update request_classifier.py for new request types
4. Test thoroughly

### Testing

```bash
# Run tests
python -m pytest tests/

# Test specific handler
python -m pytest tests/test_qna_handler.py -v
```

## üìû Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Ki·ªÉm tra logs trong debug mode
2. Verify t·∫•t c·∫£ services ƒëang ch·∫°y
3. Check API keys v√† network connectivity
4. Tham kh·∫£o troubleshooting section

**Happy coding! üöÄ**
